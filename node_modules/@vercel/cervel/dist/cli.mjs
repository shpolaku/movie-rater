import { builtinModules, createRequire } from "node:module";
import { parseArgs } from "node:util";
import { existsSync } from "node:fs";
import { lstat, readFile, rm } from "node:fs/promises";
import { dirname, extname, join, relative } from "node:path";
import { build } from "rolldown";
import { exports } from "resolve.exports";
import { isNativeError } from "node:util/types";
import { FileFsRef, debug, glob } from "@vercel/build-utils";
import { nodeFileTrace, resolve } from "@vercel/nft";
import { transform } from "oxc-transform";
import { createRequire as createRequire$1 } from "module";
import { spawn } from "child_process";
import { extname as extname$1, join as join$1 } from "path";
import { existsSync as existsSync$1 } from "fs";
import execa from "execa";
import { writeFile } from "fs/promises";

//#region src/node-file-trace.ts
const nodeFileTrace$1 = async (args) => {
	const files = {};
	const { tracedPaths } = args;
	const compiledSourceFiles = await glob("**/*", {
		cwd: args.outDir,
		follow: true,
		includeDirectories: true
	});
	for (const file of Object.keys(compiledSourceFiles)) files[file] = compiledSourceFiles[file];
	/**
	* While we're not using NFT to process source code, we are using it
	* to tree shake node deps, and include any fs reads for files that are
	* not part of the traced paths or compiled source files.
	* Most of this is identical to the `@vercel/node` implementation
	*/
	const result = await nodeFileTrace(Array.from(tracedPaths), {
		base: args.repoRootPath,
		processCwd: args.workPath,
		ts: true,
		mixedModules: true,
		async resolve(id, parent, job, cjsResolve) {
			return resolve(id, parent, job, cjsResolve);
		},
		async readFile(fsPath) {
			try {
				let source = await readFile(fsPath);
				if (fsPath.endsWith(".ts") && !fsPath.endsWith(".d.ts") || fsPath.endsWith(".tsx") || fsPath.endsWith(".mts") || fsPath.endsWith(".cts")) source = (await transform(fsPath, source.toString())).code;
				return source;
			} catch (error) {
				if (isNativeError(error) && "code" in error && (error.code === "ENOENT" || error.code === "EISDIR")) return null;
				throw error;
			}
		}
	});
	if (!args.keepTracedPaths) for (const file of tracedPaths) {
		const relativeFile = relative(args.repoRootPath, file);
		result.fileList.delete(relativeFile);
	}
	debug("NFT traced files count:", result.fileList.size);
	for (const file of result.fileList) {
		const absolutePath = join(args.repoRootPath, file);
		const stats = await lstat(absolutePath);
		const outputPath = file;
		if (stats.isSymbolicLink() || stats.isFile()) files[outputPath] = new FileFsRef({
			fsPath: absolutePath,
			mode: stats.mode
		});
	}
	debug("Total files in context:", Object.keys(files).length);
	return files;
};

//#endregion
//#region src/plugin.ts
const CJS_SHIM_PREFIX = "\0cjs-shim:";
const plugin = (args) => {
	const packageJsonCache = /* @__PURE__ */ new Map();
	const shimMeta = /* @__PURE__ */ new Map();
	const tracedPaths = /* @__PURE__ */ new Set();
	const isBareImport = (id) => {
		return !id.startsWith(".") && !id.startsWith("/") && !/^[a-z][a-z0-9+.-]*:/i.test(id);
	};
	/**
	* Read and cache package.json contents
	*/
	const getPackageJson = async (pkgPath) => {
		if (packageJsonCache.has(pkgPath)) return packageJsonCache.get(pkgPath);
		try {
			const contents = await readFile(pkgPath, "utf-8");
			const parsed = JSON.parse(contents);
			packageJsonCache.set(pkgPath, parsed);
			return parsed;
		} catch {
			packageJsonCache.set(pkgPath, null);
			return null;
		}
	};
	/**
	* Determine if a resolved module is CommonJS based on package.json exports
	*/
	const isCommonJS = async (bareImport, resolvedPath, resolvedInfo) => {
		const ext = extname(resolvedPath);
		if (ext === ".cjs") return true;
		if (ext === ".mjs") return false;
		if (ext === ".js" || ext === ".ts") {
			const pkgJsonPath = resolvedInfo.packageJsonPath;
			if (!pkgJsonPath) return true;
			const pkgJson = await getPackageJson(pkgJsonPath);
			if (!pkgJson) return true;
			const pkgDir = dirname(pkgJsonPath);
			const relativePath = resolvedPath.startsWith(pkgDir) ? resolvedPath.slice(pkgDir.length + 1).replace(/\\/g, "/") : null;
			if (!relativePath) return pkgJson.type !== "module";
			const pkgName = pkgJson.name || "";
			const subpath = bareImport.startsWith(pkgName) ? `.${bareImport.slice(pkgName.length)}` || "." : ".";
			try {
				if (exports(pkgJson, subpath, {
					require: false,
					conditions: ["node", "import"]
				})?.some((p) => p === relativePath || p === `./${relativePath}`)) return false;
				if (exports(pkgJson, subpath, {
					require: true,
					conditions: ["node", "require"]
				})?.some((p) => p === relativePath || p === `./${relativePath}`)) return true;
			} catch (err) {
				console.warn("Export resolution failed::", err);
			}
			if (pkgJson.module) return false;
			return pkgJson.type !== "module";
		}
		return true;
	};
	const isLocalImport = (id) => {
		if (id.startsWith("node:")) return false;
		if (id.includes("node_modules")) return false;
		return true;
	};
	return {
		name: "cervel",
		resolveId: {
			order: "pre",
			async handler(id, importer, rOpts) {
				if (id.startsWith(CJS_SHIM_PREFIX)) return {
					id,
					external: false
				};
				const resolved = await this.resolve(id, importer, rOpts);
				if (builtinModules.includes(id)) return {
					id: `node:${id}`,
					external: true
				};
				if (resolved?.id && isLocalImport(resolved.id)) tracedPaths.add(resolved.id);
				if (importer?.startsWith(CJS_SHIM_PREFIX) && isBareImport(id)) return {
					id,
					external: true
				};
				if (importer && isBareImport(id) && resolved?.id?.includes("node_modules")) {
					if (args.shimBareImports) {
						if (await isCommonJS(id, resolved.id, resolved)) {
							const importerPkgJsonPath = (await this.resolve(importer))?.packageJsonPath;
							if (importerPkgJsonPath) {
								const importerPkgDir = relative(args.repoRootPath, dirname(importerPkgJsonPath));
								const shimId$1 = `${CJS_SHIM_PREFIX}${importerPkgDir.replace(/\//g, "_")}_${id.replace(/\//g, "_")}`;
								shimMeta.set(shimId$1, {
									pkgDir: importerPkgDir,
									pkgName: id
								});
								return {
									id: shimId$1,
									external: false
								};
							}
							const shimId = `${CJS_SHIM_PREFIX}${id.replace(/\//g, "_")}`;
							shimMeta.set(shimId, {
								pkgDir: "",
								pkgName: id
							});
							return {
								id: shimId,
								external: false
							};
						}
					}
					return {
						external: true,
						id
					};
				}
				if (importer && isBareImport(id)) return resolved;
				return {
					external: true,
					...resolved,
					id: resolved?.id || id
				};
			}
		},
		load: { async handler(id) {
			if (id.startsWith(CJS_SHIM_PREFIX)) {
				const meta = shimMeta.get(id);
				if (!meta) return { code: `module.exports = require('${id.slice(10)}');` };
				const { pkgDir, pkgName } = meta;
				if (pkgDir) return { code: `
import { createRequire } from 'node:module';
import { fileURLToPath } from 'node:url';
import { dirname, join } from 'node:path';

const requireFromContext = createRequire(join(dirname(fileURLToPath(import.meta.url)), '${join("..", pkgDir, "package.json")}'));
module.exports = requireFromContext('${pkgName}');
`.trim() };
				return { code: `module.exports = require('${pkgName}');` };
			}
			return null;
		} },
		writeBundle: {
			order: "post",
			async handler() {
				const files = await nodeFileTrace$1({
					outDir: args.outDir,
					tracedPaths: Array.from(tracedPaths),
					repoRootPath: args.repoRootPath,
					workPath: args.workPath,
					context: args.context,
					keepTracedPaths: false
				});
				args.context.files = files;
			}
		}
	};
};

//#endregion
//#region src/rolldown.ts
const __dirname__filenameShim = `
import { createRequire as __createRequire } from 'node:module';
import { fileURLToPath as __fileURLToPath } from 'node:url';
import { dirname as __dirname_ } from 'node:path';
const require = __createRequire(import.meta.url);
const __filename = __fileURLToPath(import.meta.url);
const __dirname = __dirname_(__filename);
`.trim();
const rolldown = async (args) => {
	const entrypointPath = join(args.workPath, args.entrypoint);
	const outputDir = join(args.workPath, args.out);
	const extension = extname(args.entrypoint);
	const extensionMap = {
		".ts": {
			format: "auto",
			extension: "js"
		},
		".mts": {
			format: "esm",
			extension: "mjs"
		},
		".cts": {
			format: "cjs",
			extension: "cjs"
		},
		".cjs": {
			format: "cjs",
			extension: "cjs"
		},
		".js": {
			format: "auto",
			extension: "js"
		},
		".mjs": {
			format: "esm",
			extension: "mjs"
		}
	};
	const extensionInfo = extensionMap[extension] || extensionMap[".js"];
	let resolvedFormat = extensionInfo.format === "auto" ? void 0 : extensionInfo.format;
	const packageJsonPath = join(args.workPath, "package.json");
	const external = [];
	let pkg = {};
	if (existsSync(packageJsonPath)) {
		const source = await readFile(packageJsonPath, "utf8");
		try {
			pkg = JSON.parse(source.toString());
		} catch (_e) {
			pkg = {};
		}
		if (extensionInfo.format === "auto") if (pkg.type === "module") resolvedFormat = "esm";
		else resolvedFormat = "cjs";
		for (const dependency of Object.keys(pkg.dependencies || {})) external.push(dependency);
		for (const dependency of Object.keys(pkg.devDependencies || {})) external.push(dependency);
		for (const dependency of Object.keys(pkg.peerDependencies || {})) external.push(dependency);
		for (const dependency of Object.keys(pkg.optionalDependencies || {})) external.push(dependency);
	}
	const resolvedExtension = resolvedFormat === "esm" ? "mjs" : "cjs";
	const context = { files: {} };
	const out = await build({
		input: entrypointPath,
		cwd: args.workPath,
		platform: "node",
		tsconfig: true,
		plugins: [plugin({
			repoRootPath: args.repoRootPath,
			outDir: outputDir,
			workPath: args.workPath,
			shimBareImports: resolvedFormat === "esm",
			context
		})],
		output: {
			cleanDir: true,
			dir: outputDir,
			format: resolvedFormat,
			entryFileNames: `[name].${resolvedExtension}`,
			preserveModules: true,
			preserveModulesRoot: args.repoRootPath,
			sourcemap: false,
			banner: resolvedFormat === "esm" ? __dirname__filenameShim : void 0
		}
	});
	let handler = null;
	for (const entry of out.output) if (entry.type === "chunk") {
		if (entry.isEntry) handler = entry.fileName;
	}
	if (typeof handler !== "string") throw new Error(`Unable to resolve module for ${args.entrypoint}`);
	const cleanup = async () => {
		await rm(outputDir, {
			recursive: true,
			force: true
		});
	};
	return {
		result: {
			handler,
			outputDir,
			outputFiles: context.files
		},
		cleanup
	};
};

//#endregion
//#region src/utils.ts
const noColor = globalThis.process?.env?.NO_COLOR === "1" || globalThis.process?.env?.TERM === "dumb";
const resets = {
	1: 22,
	31: 39,
	32: 39,
	33: 39,
	34: 39,
	35: 39,
	36: 39,
	90: 39
};
const _c = (c) => (text) => {
	if (noColor) return text;
	return `\u001B[${c}m${text}\u001B[${resets[c] ?? 0}m`;
};
const Colors = {
	bold: _c(1),
	red: _c(31),
	green: _c(32),
	yellow: _c(33),
	blue: _c(34),
	magenta: _c(35),
	cyan: _c(36),
	gray: _c(90),
	url: (title, url) => noColor ? `[${title}](${url})` : `\u001B]8;;${url}\u001B\\${title}\u001B]8;;\u001B\\`
};

//#endregion
//#region src/typescript.ts
const require_ = createRequire$1(import.meta.url);
const typescript = (args) => {
	const extension = extname$1(args.entrypoint);
	if (![
		".ts",
		".mts",
		".cts"
	].includes(extension)) return;
	const tscPath = resolveTscPath(args);
	if (!tscPath) {
		console.log(Colors.gray(`${Colors.bold(Colors.cyan("✓"))} Typecheck skipped ${Colors.gray("(TypeScript not found)")}`));
		return null;
	}
	return doTypeCheck(args, tscPath);
};
async function doTypeCheck(args, tscPath) {
	let stdout = "";
	let stderr = "";
	/**
	* This might be subject to change.
	* - if no tscPath, skip typecheck
	* - if tsconfig, provide the tsconfig path
	* - else provide the entrypoint path
	*/
	const tscArgs = [
		tscPath,
		"--noEmit",
		"--pretty",
		"--allowJs",
		"--esModuleInterop",
		"--skipLibCheck"
	];
	const tsconfig = await findNearestTsconfig(args.workPath);
	if (tsconfig) tscArgs.push("--project", tsconfig);
	else tscArgs.push(args.entrypoint);
	const child = spawn(process.execPath, tscArgs, {
		cwd: args.workPath,
		stdio: [
			"ignore",
			"pipe",
			"pipe"
		]
	});
	child.stdout?.on("data", (data) => {
		stdout += data.toString();
	});
	child.stderr?.on("data", (data) => {
		stderr += data.toString();
	});
	await new Promise((resolve$1, reject) => {
		child.on("close", (code) => {
			if (code === 0) {
				console.log(Colors.gray(`${Colors.bold(Colors.cyan("✓"))} Typecheck complete`));
				resolve$1();
			} else {
				const output = stdout || stderr;
				if (output) {
					console.error("\nTypeScript type check failed:\n");
					console.error(output);
				}
				reject(/* @__PURE__ */ new Error("TypeScript type check failed"));
			}
		});
		child.on("error", (err) => {
			reject(err);
		});
	});
}
const resolveTscPath = (args) => {
	try {
		return require_.resolve("typescript/bin/tsc", { paths: [args.workPath] });
	} catch (e) {
		return null;
	}
};
const findNearestTsconfig = async (workPath) => {
	const tsconfigPath = join$1(workPath, "tsconfig.json");
	if (existsSync$1(tsconfigPath)) return tsconfigPath;
	if (workPath === "/") return;
	return findNearestTsconfig(join$1(workPath, ".."));
};

//#endregion
//#region src/find-entrypoint.ts
const frameworks = [
	"express",
	"hono",
	"elysia",
	"fastify",
	"@nestjs/core",
	"h3"
];
const entrypointFilenames = [
	"app",
	"index",
	"server",
	"main"
];
const entrypointExtensions = [
	"js",
	"cjs",
	"mjs",
	"ts",
	"cts",
	"mts"
];
const entrypoints = entrypointFilenames.flatMap((filename) => entrypointExtensions.map((extension) => `${filename}.${extension}`));
const createFrameworkRegex = (framework) => new RegExp(`(?:from|require|import)\\s*(?:\\(\\s*)?["']${framework}["']\\s*(?:\\))?`, "g");
const findEntrypoint = async (cwd, options) => {
	if (options?.ignoreRegex ?? false) {
		for (const entrypoint of entrypoints) if (existsSync(join(cwd, entrypoint))) return entrypoint;
		for (const entrypoint of entrypoints) if (existsSync(join(cwd, "src", entrypoint))) return join("src", entrypoint);
		throw new Error("No entrypoint file found");
	}
	const packageJson = await readFile(join(cwd, "package.json"), "utf-8");
	const packageJsonObject = JSON.parse(packageJson);
	const framework = frameworks.find((framework$1) => packageJsonObject.dependencies?.[framework$1]);
	if (!framework) {
		for (const entrypoint of entrypoints) {
			const entrypointPath = join(cwd, entrypoint);
			try {
				await readFile(entrypointPath, "utf-8");
				return entrypoint;
			} catch (e) {
				continue;
			}
		}
		throw new Error("No entrypoint or framework found");
	}
	const regex = createFrameworkRegex(framework);
	for (const entrypoint of entrypoints) {
		const entrypointPath = join(cwd, entrypoint);
		try {
			const content = await readFile(entrypointPath, "utf-8");
			if (regex.test(content)) return entrypoint;
		} catch (e) {
			continue;
		}
	}
	for (const entrypoint of entrypoints) {
		const entrypointPath = join(cwd, "src", entrypoint);
		try {
			const content = await readFile(entrypointPath, "utf-8");
			if (regex.test(content)) return join("src", entrypoint);
		} catch (e) {
			continue;
		}
	}
	throw new Error("No entrypoint found");
};

//#endregion
//#region src/index.ts
const require = createRequire(import.meta.url);
const build$1 = async (args) => {
	const entrypoint = args.entrypoint || await findEntrypoint(args.workPath);
	const tsPromise = typescript({
		entrypoint,
		workPath: args.workPath
	});
	const rolldownResult = await rolldown({
		entrypoint,
		workPath: args.workPath,
		repoRootPath: args.repoRootPath,
		out: args.out
	});
	await writeFile(join(args.workPath, args.out, ".cervel.json"), JSON.stringify({ handler: rolldownResult.result.handler }, null, 2));
	console.log(Colors.gray(`${Colors.bold(Colors.cyan("✓"))} Build complete`));
	const typecheckComplete = true;
	const result = tsPromise ? await Promise.race([tsPromise.then(() => typecheckComplete), Promise.resolve(false)]) : true;
	if (tsPromise && !result) console.log(Colors.gray(`${Colors.bold(Colors.gray("*"))} Waiting for typecheck...`));
	return {
		rolldownResult: rolldownResult.result,
		tsPromise
	};
};
const serve = async (args) => {
	const entrypoint = await findEntrypoint(args.workPath);
	const srvxBin = join(require.resolve("srvx"), "..", "..", "..", "bin", "srvx.mjs");
	const tsxBin = require.resolve("tsx");
	const restArgs = Object.entries(args.rest).filter(([, value]) => value !== void 0 && value !== false).map(([key, value]) => typeof value === "boolean" ? `--${key}` : `--${key}=${value}`);
	if (!args.rest.import) restArgs.push("--import", tsxBin);
	await execa("npx", [
		srvxBin,
		...restArgs,
		entrypoint
	], {
		cwd: args.workPath,
		stdio: "inherit"
	});
};
const srvxOptions = {
	help: {
		type: "boolean",
		short: "h"
	},
	version: {
		type: "boolean",
		short: "v"
	},
	prod: { type: "boolean" },
	port: {
		type: "string",
		short: "p"
	},
	host: {
		type: "string",
		short: "H"
	},
	static: {
		type: "string",
		short: "s"
	},
	import: { type: "string" },
	tls: { type: "boolean" },
	cert: { type: "string" },
	key: { type: "string" }
};

//#endregion
//#region src/cli.ts
const main = async () => {
	const options = parseArgs$1(process.argv.slice(2));
	const { cwd, out,...rest } = options.values;
	const [command, entrypoint] = options.positionals;
	const workPath = cwd;
	const repoRootPath = cwd;
	if (command === "build") {
		const { tsPromise } = await build$1({
			workPath,
			repoRootPath,
			out,
			entrypoint
		});
		await tsPromise;
	} else await serve({
		workPath,
		rest
	});
};
function parseArgs$1(args) {
	const { values, positionals } = parseArgs({
		args,
		allowPositionals: true,
		options: {
			cwd: {
				type: "string",
				default: process.cwd()
			},
			out: {
				type: "string",
				default: "dist"
			},
			...srvxOptions
		}
	});
	return {
		values,
		positionals
	};
}

//#endregion
export { main };